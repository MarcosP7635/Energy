{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Unitful #https://painterqubits.github.io/Unitful.jl/stable/\n",
    "#quantity * @u_str(\"unit abbreviation\") \n",
    "using Symbolics #https://symbolics.juliasymbolics.org/dev/\n",
    "#cite https://doi.org/10.48550/arXiv.2105.03949\n",
    "using Latexify\n",
    "using Test\n",
    "#1 * @u_str(\"mA\") is 1 milliamp\n",
    "using CSV, DataFrames\n",
    "#using Plots\n",
    "using PlotlyJS\n",
    "using Printf\n",
    "using SymPy\n",
    "using PDFIO\n",
    "using Unzip\n",
    "using Interpolations\n",
    "using Plots\n",
    "using TensorCast\n",
    "#plotlyjs()\n",
    "data_dir = \"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it faster use a matrix or run more loops? Probably just to run more loops. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Any, Any} with 18 entries:\n",
       "  \"Targ\"       => [92238.0, 92238.0, 92238.0, 92238.0, 92238.0, 92238.0, 92238.…\n",
       "  \"Entry\"      => SubString{String}[\"V0015\", \"V0015\", \"V0015\", \"V0015\", \"V0015\"…\n",
       "  \"dCos/LO\"    => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"I78\"        => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"dEnergy\"    => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"dELV/HL\"    => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"M\"          => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"Refer (YY)\" => SubString{String}[\"F.Manero,ET.AL. (72)\", \"F.Manero,ET.AL. (7…\n",
       "  \"Prj\"        => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.…\n",
       "  \"Energy\"     => Any[1.25e6, 1.275e6, 1.3e6, 1.325e6, 1.35e6, 1.375e6, 1.4e6, …\n",
       "  \"Cos/LO\"     => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"ELV/HL\"     => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"MF\"         => [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0  …  1.0, 1.…\n",
       "  \"dData\"      => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"Data\"       => [2.5863, 2.587, 2.5878, 2.5886, 2.5896, 2.5906, 2.5917, 2.592…\n",
       "  \"Sub\"        => [16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0, 16.0  …\n",
       "  \"PXC\"        => SubString{String}[\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"  …  …\n",
       "  \"MT\"         => [452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.0, 452.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = data_dir * \"neutrons\\\\092_U_238.c4\"\n",
    "file_as_vector = readlines(file_path)\n",
    "max_line_length = maximum(length.(file_as_vector))\n",
    "l = length(file_as_vector)\n",
    "spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "if check_line(file_as_vector[index], \"# Prj\")]\n",
    "index = spacing_specifiers[1]\n",
    "spacing_dict = make_spacing_dict(file_as_vector[index], file_as_vector[index + 1])\n",
    "spacing_keys = [key for key in keys(spacing_dict)]\n",
    "lines_of_data = tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "data_dict = Dict([])\n",
    "filler = [data_dict[key] = [read_datum(file_as_vector[line_num][spacing_dict[key]])\n",
    "            for line_num in index + 2: index + 1 + lines_of_data] for key in spacing_keys]   \n",
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Design\n",
    "\n",
    "    Looping check_line() through each line in the file detects where each dataset begins. \n",
    "\n",
    "    Reading the line above each output of check_line() gives the number of rows in each dataset.\n",
    "\n",
    "    make_spacing_dict() gets the names of the columns and the instructions for how to read each dataset.\n",
    "\n",
    "    read_dataset() reads each and constructs a dataframe from each dataset.\n",
    "    \n",
    "    combine_datasets() creates vertically concatenates each dataset.\n",
    "\n",
    "    read_exfor_file() runs all of the above in order to return a single DataFrame of a given file path.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_dataset (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function check_line(line, start)\n",
    "    if length(line) > length(start) - 1\n",
    "        return (line[1:length(start)] == start)\n",
    "    end\n",
    "    return false\n",
    "end\n",
    "\n",
    "function make_spacing_dict(line1, line2)\n",
    "    spacing_ends = [collect(out)[1] for out in findall(\">\", line2)]\n",
    "    spacing_starts = append!([1], [collect(out)[1] for out in findall(\"<\", line2)])\n",
    "    #Find where some of the spacings begin and end based on the arrows\n",
    "    if length(spacing_ends) != length(spacing_starts)\n",
    "        print(\"Error: improper formatting\")\n",
    "        return \n",
    "    end\n",
    "    indices_with_gaps = [index for index in  1:length(spacing_ends)-1 if \n",
    "                    spacing_ends[index] != spacing_starts[index+1]-1]\n",
    "    #Some of the spacings are instead denoted by the letter o instead of arrows\n",
    "    missing_spacings = [spacing_ends[index]+1:spacing_starts[index+1]-1 for index in indices_with_gaps]\n",
    "    spacings = append!(missing_spacings, \n",
    "    [spacing_starts[i]:spacing_ends[i] for i in 1:length(spacing_ends)])\n",
    "    spacing_dict = Dict([])\n",
    "    #Make a dictionary where the keys are name for each column and the values are the indices of the columns\n",
    "    spacing_names = [spacing_dict[strip(line1[spacing], [' ', '#'])] = spacing for spacing in spacings]\n",
    "    return spacing_dict\n",
    "end\n",
    "\n",
    "function read_datum(datum)\n",
    "    #Reads a single datum from a line of data\n",
    "    datum = strip(datum, [' '])\n",
    "    out = tryparse(Float64, datum)\n",
    "    if out == nothing\n",
    "        return datum \n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function read_dataset(spacing_specifier, file_as_vector)\n",
    "    index = spacing_specifier\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[index], file_as_vector[index + 1])\n",
    "    lines_of_data = tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "    data_dict = Dict([])\n",
    "    filler = [data_dict[key] = [read_datum(file_as_vector[line_num][spacing_dict[key]])\n",
    "            for line_num in index + 2: index + 1 + lines_of_data] for key in keys(spacing_dict)]    \n",
    "    return data_dict\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It it faster to use 1 or loop for $n$ list comprehensions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_exfor_file (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function read_exfor_file(file_path)\n",
    "    #Reads an EXFOR file and returns a dictionary of data\n",
    "    file_as_vector = readlines(file_path)\n",
    "    max_line_length = maximum(length.(file_as_vector))\n",
    "    spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "    if check_line(file_as_vector[index], \"# Prj\")]\n",
    "    #Split the file into lines\n",
    "    #Find the line that starts with \"Data\"\n",
    "    #==\n",
    "    for index in 1:length(file_as_vector)\n",
    "        if check_line(file_as_vector[index], \"# Prj\")\n",
    "            rows_in_dataset = tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "            spacing_dict = make_spacing_dict(file_as_vector[index], file_as_vector[index + 1])\n",
    "            data_dict = Dict([])\n",
    "            filler = [data_dict[key] =  [read_datum(\n",
    "                    file_as_matrix[index + 2 : index + 1 + rows_in_dataset,spacing_dict[key]])\n",
    "                    for key in keys(spacing_dict)]]    \n",
    "        end\n",
    "    end\n",
    "    ==#\n",
    "    if spacing_specifiers == []\n",
    "        print(\"Error: no data found\")\n",
    "        return\n",
    "    end\n",
    "    rows_in_each_dataset = [tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "                            for index in spacing_specifiers]    \n",
    "    top_of_each_dataset = [sum(rows_in_each_dataset[1:index]) \n",
    "                            for index in 1:length(rows_in_each_dataset)]\n",
    "    #Each dataset should have the same column names\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[spacing_specifiers[1]], \n",
    "                    file_as_vector[spacing_specifiers[1] + 1])\n",
    "    spacing_keys = [key for key in keys(spacing_dict)]\n",
    "    #make an empty dataframe to fill up with the data\n",
    "    rows_in_df = sum(rows_in_each_dataset)\n",
    "    df = DataFrame([Vector{Union{Missing, Float64, String, SubString{String}}}(missing, rows_in_df) \n",
    "                    for _ in 1:length(spacing_keys)], spacing_keys)\n",
    "    #Fill the dataframe with the data\n",
    "    top_dataset = read_dataset(spacing_specifiers[1], file_as_vector)\n",
    "    _ = [df[1:rows_in_each_dataset[1], key] = top_dataset[key] for key in spacing_keys]\n",
    "    print(\"hi\")\n",
    "    _ = [[df[top_of_each_dataset[index-1]:top_of_each_dataset[index]-1, key] = \n",
    "            read_dataset(spacing_specifiers[index], file_as_vector)[key] \n",
    "            for key in spacing_keys] for index in 2:length(top_of_each_dataset)]\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>225 rows × 18 columns (omitted printing of 10 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Targ</th><th>Entry</th><th>dCos/LO</th><th>I78</th><th>dEnergy</th><th>dELV/HL</th><th>M</th><th>Refer (YY)</th></tr><tr><th></th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th></tr></thead><tbody><tr><th>1</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>2</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>3</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>4</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>5</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>6</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>7</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>8</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>9</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>10</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>11</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>12</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>13</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>14</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>15</th><td>1001.0</td><td>K2066</td><td></td><td></td><td>4.0000+7</td><td></td><td></td><td>S.Homma,ET.AL. (74)</td></tr><tr><th>16</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>510000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>17</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>540000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>18</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>570000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>19</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>600000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>20</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>630000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>21</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>660000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>22</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>690000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>23</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>720000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>24</th><td>1001.0</td><td>M0519</td><td></td><td></td><td>750000.0</td><td></td><td></td><td>M.Maccormick,ET.AL. (96)</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Targ & Entry & dCos/LO & I78 & dEnergy & dELV/HL & M & Refer (YY) & \\\\\n",
       "\t\\hline\n",
       "\t& Union…? & Union…? & Union…? & Union…? & Union…? & Union…? & Union…? & Union…? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t2 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t3 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t4 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t5 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t6 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t7 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t8 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t9 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t10 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t11 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t12 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t13 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t14 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t15 & 1001.0 & K2066 &  &  & 4.0000+7 &  &  & S.Homma,ET.AL. (74) & $\\dots$ \\\\\n",
       "\t16 & 1001.0 & M0519 &  &  & 510000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t17 & 1001.0 & M0519 &  &  & 540000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t18 & 1001.0 & M0519 &  &  & 570000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t19 & 1001.0 & M0519 &  &  & 600000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t20 & 1001.0 & M0519 &  &  & 630000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t21 & 1001.0 & M0519 &  &  & 660000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t22 & 1001.0 & M0519 &  &  & 690000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t23 & 1001.0 & M0519 &  &  & 720000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t24 & 1001.0 & M0519 &  &  & 750000.0 &  &  & M.Maccormick,ET.AL. (96) & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m225×18 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Targ    \u001b[0m\u001b[1m Entry   \u001b[0m\u001b[1m dCos/LO \u001b[0m\u001b[1m I78     \u001b[0m\u001b[1m dEnergy  \u001b[0m\u001b[1m dELV/HL \u001b[0m\u001b[1m M       \u001b[0m\u001b[1m Refer (\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…?  \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…?\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 1001.0   K2066                      4.0000+7                    S.Homma ⋯\n",
       "   2 │ 1001.0   K2066                      4.0000+7                    S.Homma\n",
       "   3 │ 1001.0   K2066                      4.0000+7                    S.Homma\n",
       "   4 │ 1001.0   K2066                      4.0000+7                    S.Homma\n",
       "   5 │ 1001.0   K2066                      4.0000+7                    S.Homma ⋯\n",
       "   6 │ 1001.0   K2066                      4.0000+7                    S.Homma\n",
       "   7 │ 1001.0   K2066                      4.0000+7                    S.Homma\n",
       "   8 │ 1001.0   K2066                      4.0000+7                    S.Homma\n",
       "  ⋮  │    ⋮        ⋮        ⋮        ⋮        ⋮         ⋮        ⋮             ⋱\n",
       " 219 │ 1001.0   M0521                                                  A.Hunge ⋯\n",
       " 220 │ 1001.0   M0521                                                  A.Hunge\n",
       " 221 │ 1001.0   M0521                                                  A.Hunge\n",
       " 222 │ 1001.0   M0521                                                  A.Hunge\n",
       " 223 │ 1001.0   M0521                                                  A.Hunge ⋯\n",
       " 224 │ 1001.0   M0521                                                  A.Hunge\n",
       " 225 │\u001b[90m missing \u001b[0m\u001b[90m missing \u001b[0m\u001b[90m missing \u001b[0m\u001b[90m missing \u001b[0m\u001b[90m missing  \u001b[0m\u001b[90m missing \u001b[0m\u001b[90m missing \u001b[0m\u001b[90m missing\u001b[0m\n",
       "\u001b[36m                                                 11 columns and 210 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "read_exfor_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274785dbb282d05f4e0ae2ca70ac66f1fa0484127cd60ef9f4ac2dd997977034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
