{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Unitful #https://painterqubits.github.io/Unitful.jl/stable/\n",
    "#quantity * @u_str(\"unit abbreviation\") \n",
    "using Symbolics #https://symbolics.juliasymbolics.org/dev/\n",
    "#cite https://doi.org/10.48550/arXiv.2105.03949\n",
    "using Latexify\n",
    "using Test\n",
    "#1 * @u_str(\"mA\") is 1 milliamp\n",
    "using CSV, DataFrames\n",
    "#using Plots\n",
    "using PlotlyJS\n",
    "using Printf\n",
    "using SymPy\n",
    "using PDFIO\n",
    "using Unzip\n",
    "using Interpolations\n",
    "using Plots\n",
    "using TensorCast\n",
    "#plotlyjs()\n",
    "data_dir = \"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Design\n",
    "\n",
    "    Looping check_line() through each line in the file detects where each dataset begins. \n",
    "\n",
    "    Reading the line above each output of check_line() gives the number of rows in each dataset.\n",
    "\n",
    "    make_spacing_dict() gets the names of the columns and the instructions for how to read each dataset.\n",
    "\n",
    "    read_dataset() reads each and constructs a dictionary from each dataset.\n",
    "    \n",
    "    read_exfor_file() runs all of the above in order to return a single DataFrame of all the data stored at a given file path.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_dataset (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function check_line(line, start)\n",
    "    if length(line) > length(start) - 1\n",
    "        return (line[1:length(start)] == start)\n",
    "    end\n",
    "    return false\n",
    "end\n",
    "\n",
    "function make_spacing_dict(line1, line2)\n",
    "    spacing_ends = [collect(out)[1] for out in findall(\">\", line2)]\n",
    "    spacing_starts = append!([1], [collect(out)[1] for out in findall(\"<\", line2)])\n",
    "    #Find where some of the spacings begin and end based on the arrows\n",
    "    if length(spacing_ends) != length(spacing_starts)\n",
    "        print(\"Error: improper formatting\")\n",
    "        return \n",
    "    end\n",
    "    indices_with_gaps = [index for index in  1:length(spacing_ends)-1 if \n",
    "                    spacing_ends[index] != spacing_starts[index+1]-1]\n",
    "    #Some of the spacings are instead denoted by the letter o instead of arrows\n",
    "    missing_spacings = [spacing_ends[index]+1:spacing_starts[index+1]-1 for index in indices_with_gaps]\n",
    "    spacings = append!(missing_spacings, \n",
    "    [spacing_starts[i]:spacing_ends[i] for i in 1:length(spacing_ends)])\n",
    "    spacing_dict = Dict([])\n",
    "    #Make a dictionary where the keys are name for each column and the values are the indices of the columns\n",
    "    spacing_names = [spacing_dict[strip(line1[spacing], [' ', '#'])] = spacing for spacing in spacings]\n",
    "    return spacing_dict\n",
    "end\n",
    "\n",
    "function read_datum(datum)\n",
    "    #Reads a single datum from a line of data\n",
    "    datum = strip(datum, [' '])\n",
    "    out = tryparse(Float64, datum)\n",
    "    if out == nothing\n",
    "        return datum \n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function read_dataset(spacing_specifier, file_as_vector)\n",
    "    index = spacing_specifier\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[index], file_as_vector[index + 1])\n",
    "    lines_of_data = tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "    data_dict = Dict([])\n",
    "    filler = [data_dict[key] = [read_datum(file_as_vector[line_num][spacing_dict[key]])\n",
    "            for line_num in index + 2: index + 1 + lines_of_data] for key in keys(spacing_dict)]\n",
    "    return data_dict#, lines_of_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It it faster to use 1 or loop for $n$ list comprehensions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_exfor_file (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function read_exfor_file(file_path)\n",
    "    #Reads an EXFOR file and returns a dictionary of data\n",
    "    file_as_vector = readlines(file_path)\n",
    "    spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "                        if check_line(file_as_vector[index], \"# Prj\")]\n",
    "    if spacing_specifiers == []\n",
    "        print(\"Error: no data found\")\n",
    "        return\n",
    "    end\n",
    "    #rows_in_combined_df = sum([tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "    #                for index in spacing_specifiers])\n",
    "    #Each dataset should have the same column names\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[spacing_specifiers[1]], \n",
    "                    file_as_vector[spacing_specifiers[1] + 1])\n",
    "    spacing_keys = [key for key in keys(spacing_dict)]\n",
    "    #make an empty dataframe to fill up with the data\n",
    "    #df = DataFrame([Vector{Union{Missing, Float64, String, SubString{String}}}(missing, rows_in_combined_df) \n",
    "    #                for _ in 1:length(spacing_keys)], spacing_keys)\n",
    "    #Fill the dataframe with the data\n",
    "    #current_row = 1\n",
    "    #This for loop is probably the slowest part of the code. It alone takes over 50% of the runtime.  \n",
    "    print(\"hi\")\n",
    "    df = reduce(vcat,[DataFrame(read_dataset(spacing_specifiers[i], file_as_vector)) \n",
    "            for i in 1:length(spacing_specifiers)])\n",
    "    #==\n",
    "    for spacing_specifier in spacing_specifiers\n",
    "        data_dict, rows_in_dataset = read_dataset(spacing_specifier, file_as_vector)\n",
    "        _ = [df[current_row:current_row+rows_in_dataset-1, key] = data_dict[key]\n",
    "            for key in keys(data_dict)]\n",
    "        current_row += rows_in_dataset\n",
    "    end\n",
    "    ==#\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>236,005 rows × 18 columns (omitted printing of 9 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Cos/LO</th><th>Data</th><th>ELV/HL</th><th>Energy</th><th>Entry</th><th>I78</th><th>M</th><th>MF</th><th>MT</th></tr><tr><th></th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"SubString{String}\">SubStrin…</th><th title=\"SubString{String}\">SubStrin…</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td></td><td>2.5863</td><td></td><td>1.25e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>2</th><td></td><td>2.587</td><td></td><td>1.275e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>3</th><td></td><td>2.5878</td><td></td><td>1.3e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>4</th><td></td><td>2.5886</td><td></td><td>1.325e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>5</th><td></td><td>2.5896</td><td></td><td>1.35e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>6</th><td></td><td>2.5906</td><td></td><td>1.375e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>7</th><td></td><td>2.5917</td><td></td><td>1.4e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>8</th><td></td><td>2.5929</td><td></td><td>1.425e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>9</th><td></td><td>2.5941</td><td></td><td>1.45e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>10</th><td></td><td>2.5955</td><td></td><td>1.475e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>11</th><td></td><td>2.5969</td><td></td><td>1.5e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>12</th><td></td><td>2.5999</td><td></td><td>1.55e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>13</th><td></td><td>2.6032</td><td></td><td>1.6e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>14</th><td></td><td>2.6067</td><td></td><td>1.65e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>15</th><td></td><td>2.6105</td><td></td><td>1.7e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>16</th><td></td><td>2.6146</td><td></td><td>1.75e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>17</th><td></td><td>2.6189</td><td></td><td>1.8e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>18</th><td></td><td>2.6233</td><td></td><td>1.85e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>19</th><td></td><td>2.6282</td><td></td><td>1.9e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>20</th><td></td><td>2.6332</td><td></td><td>1.95e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>21</th><td></td><td>2.6384</td><td></td><td>2.0e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>22</th><td></td><td>2.6494</td><td></td><td>2.1e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>23</th><td></td><td>2.6612</td><td></td><td>2.2e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>24</th><td></td><td>2.6736</td><td></td><td>2.3e6</td><td>V0015</td><td></td><td></td><td>1.0</td><td>452.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& Cos/LO & Data & ELV/HL & Energy & Entry & I78 & M & MF & MT & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & Any & Any & Any & SubStrin… & SubStrin… & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 &  & 2.5863 &  & 1.25e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t2 &  & 2.587 &  & 1.275e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t3 &  & 2.5878 &  & 1.3e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t4 &  & 2.5886 &  & 1.325e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t5 &  & 2.5896 &  & 1.35e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t6 &  & 2.5906 &  & 1.375e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t7 &  & 2.5917 &  & 1.4e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t8 &  & 2.5929 &  & 1.425e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t9 &  & 2.5941 &  & 1.45e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t10 &  & 2.5955 &  & 1.475e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t11 &  & 2.5969 &  & 1.5e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t12 &  & 2.5999 &  & 1.55e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t13 &  & 2.6032 &  & 1.6e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t14 &  & 2.6067 &  & 1.65e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t15 &  & 2.6105 &  & 1.7e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t16 &  & 2.6146 &  & 1.75e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t17 &  & 2.6189 &  & 1.8e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t18 &  & 2.6233 &  & 1.85e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t19 &  & 2.6282 &  & 1.9e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t20 &  & 2.6332 &  & 1.95e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t21 &  & 2.6384 &  & 2.0e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t22 &  & 2.6494 &  & 2.1e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t23 &  & 2.6612 &  & 2.2e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t24 &  & 2.6736 &  & 2.3e6 & V0015 &  &  & 1.0 & 452.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m236005×18 DataFrame\u001b[0m\n",
       "\u001b[1m    Row \u001b[0m│\u001b[1m Cos/LO \u001b[0m\u001b[1m Data   \u001b[0m\u001b[1m ELV/HL   \u001b[0m\u001b[1m Energy  \u001b[0m\u001b[1m Entry   \u001b[0m\u001b[1m I78       \u001b[0m\u001b[1m M         \u001b[0m\u001b[1m MF\u001b[0m ⋯\n",
       "\u001b[1m        \u001b[0m│\u001b[90m Any    \u001b[0m\u001b[90m Any    \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m SubStrin… \u001b[0m\u001b[90m SubStrin… \u001b[0m\u001b[90m Fl\u001b[0m ⋯\n",
       "────────┼───────────────────────────────────────────────────────────────────────\n",
       "      1 │         2.5863            1.25e6   V0015                             ⋯\n",
       "      2 │         2.587             1.275e6  V0015\n",
       "      3 │         2.5878            1.3e6    V0015\n",
       "      4 │         2.5886            1.325e6  V0015\n",
       "      5 │         2.5896            1.35e6   V0015                             ⋯\n",
       "      6 │         2.5906            1.375e6  V0015\n",
       "      7 │         2.5917            1.4e6    V0015\n",
       "      8 │         2.5929            1.425e6  V0015\n",
       "   ⋮    │   ⋮       ⋮        ⋮         ⋮        ⋮         ⋮          ⋮         ⋱\n",
       " 235999 │         1.0     2.0900+8  5.8e6    22402.0  E2                       ⋯\n",
       " 236000 │         3.0     2.1000+8  5.8e6    22402.0  E2\n",
       " 236001 │         1.0     2.1100+8  5.8e6    22402.0  E2\n",
       " 236002 │         1.0     2.1200+8  5.8e6    22402.0  E2\n",
       " 236003 │         1.0     2.1600+8  5.8e6    22402.0  E2                       ⋯\n",
       " 236004 │         1.0     2.1900+8  5.8e6    22402.0  E2\n",
       " 236005 │         1.0     2.2200+8  5.8e6    22402.0  E2\n",
       "\u001b[36m                                              11 columns and 235990 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = data_dir * \"neutrons\\\\001_H_001.c4\"\n",
    "read_exfor_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274785dbb282d05f4e0ae2ca70ac66f1fa0484127cd60ef9f4ac2dd997977034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
