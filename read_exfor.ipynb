{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "using Unitful #https://painterqubits.github.io/Unitful.jl/stable/\n",
    "#quantity * @u_str(\"unit abbreviation\") \n",
    "using Symbolics #https://symbolics.juliasymbolics.org/dev/\n",
    "#cite https://doi.org/10.48550/arXiv.2105.03949\n",
    "using Latexify\n",
    "using Test\n",
    "#1 * @u_str(\"mA\") is 1 milliamp\n",
    "using CSV, DataFrames\n",
    "#using Plots\n",
    "using PlotlyJS\n",
    "using Printf\n",
    "using SymPy\n",
    "using PDFIO\n",
    "using Unzip\n",
    "using Interpolations\n",
    "using Plots\n",
    "using TensorCast\n",
    "#plotlyjs()\n",
    "data_dir = \"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Design\n",
    "\n",
    "    Looping check_line() through each line in the file detects where each dataset begins. \n",
    "\n",
    "    Reading the line above each output of check_line() gives the number of rows in each dataset.\n",
    "\n",
    "    make_spacing_dict() gets the names of the columns and the instructions for how to read each dataset.\n",
    "\n",
    "    read_dataset() reads each and constructs a dictionary from each dataset.\n",
    "    \n",
    "    read_exfor_file() runs all of the above in order to return a single DataFrame of all the data stored at a given file path.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_dataset (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function check_line(line, start)\n",
    "    if length(line) > length(start) - 1\n",
    "        return (line[1:length(start)] == start)\n",
    "    end\n",
    "    return false\n",
    "end\n",
    "\n",
    "function make_spacing_dict(line1, line2)\n",
    "    spacing_ends = [collect(out)[1] for out in findall(\">\", line2)]\n",
    "    spacing_starts = append!([1], [collect(out)[1] for out in findall(\"<\", line2)])\n",
    "    #Find where some of the spacings begin and end based on the arrows\n",
    "    if length(spacing_ends) != length(spacing_starts)\n",
    "        print(\"Error: improper formatting\")\n",
    "        return \n",
    "    end\n",
    "    indices_with_gaps = [index for index in  1:length(spacing_ends)-1 if \n",
    "                    spacing_ends[index] != spacing_starts[index+1]-1]\n",
    "    #Some of the spacings are instead denoted by the letter o instead of arrows\n",
    "    missing_spacings = [spacing_ends[index]+1:spacing_starts[index+1]-1 for index in indices_with_gaps]\n",
    "    spacings = append!(missing_spacings, \n",
    "    [spacing_starts[i]:spacing_ends[i] for i in 1:length(spacing_ends)])\n",
    "    spacing_dict = Dict([])\n",
    "    #Make a dictionary where the keys are name for each column and the values are the indices of the columns\n",
    "    spacing_names = [spacing_dict[strip(line1[spacing], [' ', '#'])] = spacing for spacing in spacings]\n",
    "    return spacing_dict\n",
    "end\n",
    "\n",
    "function read_datum(datum)\n",
    "    #Reads a single datum from a line of data\n",
    "    datum = strip(datum, [' '])\n",
    "    out = tryparse(Float64, datum)\n",
    "    if out == nothing\n",
    "        return datum \n",
    "    end\n",
    "    return out\n",
    "end\n",
    "\n",
    "function read_dataset(spacing_specifier, file_as_vector)\n",
    "    index = spacing_specifier\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[index], file_as_vector[index + 1])\n",
    "    lines_of_data = tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "    data_dict = Dict([])\n",
    "    filler = [data_dict[key] = [read_datum(file_as_vector[line_num][spacing_dict[key]])\n",
    "            for line_num in index + 2: index + 1 + lines_of_data] for key in keys(spacing_dict)]\n",
    "    return data_dict#, lines_of_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It it faster to use 1 or loop for $n$ list comprehensions? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_exfor_file (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function read_exfor_file(file_path)\n",
    "    #Reads an EXFOR file and returns a dictionary of data\n",
    "    file_as_vector = readlines(file_path)\n",
    "    spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "                        if check_line(file_as_vector[index], \"# Prj\")]\n",
    "    if spacing_specifiers == []\n",
    "        print(\"Error: no data found\")\n",
    "        return\n",
    "    end\n",
    "    #rows_in_combined_df = sum([tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "    #                for index in spacing_specifiers])\n",
    "    #Each dataset should have the same column names\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[spacing_specifiers[1]], \n",
    "                    file_as_vector[spacing_specifiers[1] + 1])\n",
    "    spacing_keys = [key for key in keys(spacing_dict)]\n",
    "    #make an empty dataframe to fill up with the data\n",
    "    #df = DataFrame([Vector{Union{Missing, Float64, String, SubString{String}}}(missing, rows_in_combined_df) \n",
    "    #                for _ in 1:length(spacing_keys)], spacing_keys)\n",
    "    #Fill the dataframe with the data\n",
    "    #current_row = 1\n",
    "    #This for loop is probably the slowest part of the code. It alone takes over 50% of the runtime.  \n",
    "    df = reduce(vcat,[DataFrame(read_dataset(spacing_specifiers[i], file_as_vector)) \n",
    "            for i in 1:length(spacing_specifiers)])\n",
    "    #==\n",
    "    for spacing_specifier in spacing_specifiers\n",
    "        data_dict, rows_in_dataset = read_dataset(spacing_specifier, file_as_vector)\n",
    "        _ = [df[current_row:current_row+rows_in_dataset-1, key] = data_dict[key]\n",
    "            for key in keys(data_dict)]\n",
    "        current_row += rows_in_dataset\n",
    "    end\n",
    "    ==#\n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>9,539 rows × 18 columns (omitted printing of 9 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Cos/LO</th><th>Data</th><th>ELV/HL</th><th>Energy</th><th>Entry</th><th>I78</th><th>M</th><th>MF</th><th>MT</th></tr><tr><th></th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"SubString{String}\">SubStrin…</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th><th title=\"SubString{String}\">SubStrin…</th><th title=\"SubString{String}\">SubStrin…</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td></td><td>84.569</td><td></td><td>2.8190-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>2</th><td></td><td>82.341</td><td></td><td>3.5070-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>3</th><td></td><td>80.112</td><td></td><td>4.1930-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>4</th><td></td><td>77.711</td><td></td><td>4.9150-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>5</th><td></td><td>75.311</td><td></td><td>5.9940-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>6</th><td></td><td>73.081</td><td></td><td>7.0260-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>7</th><td></td><td>69.994</td><td></td><td>8.4020-3</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>8</th><td></td><td>67.594</td><td></td><td>0.01005</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>9</th><td></td><td>65.021</td><td></td><td>0.01178</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>10</th><td></td><td>62.619</td><td></td><td>0.01327</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>11</th><td></td><td>59.875</td><td></td><td>0.01556</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>12</th><td></td><td>55.415</td><td></td><td>0.02014</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>13</th><td></td><td>52.328</td><td></td><td>0.02457</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>14</th><td></td><td>49.927</td><td></td><td>0.0288</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>15</th><td></td><td>47.354</td><td></td><td>0.03377</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>16</th><td></td><td>44.61</td><td></td><td>0.03959</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>17</th><td></td><td>41.352</td><td></td><td>0.05024</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>18</th><td></td><td>39.809</td><td></td><td>0.05659</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>19</th><td></td><td>38.095</td><td></td><td>0.06633</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>20</th><td></td><td>35.866</td><td></td><td>0.07931</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>21</th><td></td><td>33.638</td><td></td><td>0.1006</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>22</th><td></td><td>31.926</td><td></td><td>0.1251</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>23</th><td></td><td>29.87</td><td></td><td>0.1619</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>24</th><td></td><td>28.672</td><td></td><td>0.1974</td><td>11432.0</td><td></td><td></td><td>3.0</td><td>1.0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& Cos/LO & Data & ELV/HL & Energy & Entry & I78 & M & MF & MT & \\\\\n",
       "\t\\hline\n",
       "\t& Any & Any & SubStrin… & Any & Any & SubStrin… & SubStrin… & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 &  & 84.569 &  & 2.8190-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t2 &  & 82.341 &  & 3.5070-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t3 &  & 80.112 &  & 4.1930-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t4 &  & 77.711 &  & 4.9150-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t5 &  & 75.311 &  & 5.9940-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t6 &  & 73.081 &  & 7.0260-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t7 &  & 69.994 &  & 8.4020-3 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t8 &  & 67.594 &  & 0.01005 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t9 &  & 65.021 &  & 0.01178 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t10 &  & 62.619 &  & 0.01327 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t11 &  & 59.875 &  & 0.01556 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t12 &  & 55.415 &  & 0.02014 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t13 &  & 52.328 &  & 0.02457 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t14 &  & 49.927 &  & 0.0288 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t15 &  & 47.354 &  & 0.03377 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t16 &  & 44.61 &  & 0.03959 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t17 &  & 41.352 &  & 0.05024 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t18 &  & 39.809 &  & 0.05659 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t19 &  & 38.095 &  & 0.06633 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t20 &  & 35.866 &  & 0.07931 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t21 &  & 33.638 &  & 0.1006 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t22 &  & 31.926 &  & 0.1251 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t23 &  & 29.87 &  & 0.1619 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t24 &  & 28.672 &  & 0.1974 & 11432.0 &  &  & 3.0 & 1.0 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m9539×18 DataFrame\u001b[0m\n",
       "\u001b[1m  Row \u001b[0m│\u001b[1m Cos/LO \u001b[0m\u001b[1m Data    \u001b[0m\u001b[1m ELV/HL    \u001b[0m\u001b[1m Energy   \u001b[0m\u001b[1m Entry   \u001b[0m\u001b[1m I78       \u001b[0m\u001b[1m M         \u001b[0m\u001b[1m M\u001b[0m ⋯\n",
       "\u001b[1m      \u001b[0m│\u001b[90m Any    \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m SubStrin… \u001b[0m\u001b[90m Any      \u001b[0m\u001b[90m Any     \u001b[0m\u001b[90m SubStrin… \u001b[0m\u001b[90m SubStrin… \u001b[0m\u001b[90m F\u001b[0m ⋯\n",
       "──────┼─────────────────────────────────────────────────────────────────────────\n",
       "    1 │         84.569              2.8190-3  11432.0                          ⋯\n",
       "    2 │         82.341              3.5070-3  11432.0\n",
       "    3 │         80.112              4.1930-3  11432.0\n",
       "    4 │         77.711              4.9150-3  11432.0\n",
       "    5 │         75.311              5.9940-3  11432.0                          ⋯\n",
       "    6 │         73.081              7.0260-3  11432.0\n",
       "    7 │         69.994              8.4020-3  11432.0\n",
       "    8 │         67.594              0.01005   11432.0\n",
       "  ⋮   │   ⋮        ⋮         ⋮         ⋮         ⋮         ⋮          ⋮        ⋱\n",
       " 9533 │ 2.9     1.02                6.1e6     20389.0                          ⋯\n",
       " 9534 │ 2.9     0.98                6.2e6     20389.0\n",
       " 9535 │ 2.9     0.992               1.7e6     20389.0\n",
       " 9536 │ 2.9     0.995               5.0e6     20389.0\n",
       " 9537 │ 2.9     1.07                2.46e6    30327.0                          ⋯\n",
       " 9538 │ 2.9     1.865               2.72e6    30340.0\n",
       " 9539 │ 102.9   0.02506             1.5e6     30971.0\n",
       "\u001b[36m                                                11 columns and 9524 rows omitted\u001b[0m"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path = data_dir * \"neutrons\\\\001_H_001.c4\"\n",
    "read_exfor_file(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maybe consider using CatViews? \n",
    "\n",
    "https://www.juliapackages.com/p/catviews \n",
    "\n",
    "https://stackoverflow.com/questions/46301279/julia-efficient-ways-to-vcat-n-arrays \n",
    "\n",
    "method5(json_in) = reduce(CatView, mappedarray(x->x[\"transactions\"], json_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "274785dbb282d05f4e0ae2ca70ac66f1fa0484127cd60ef9f4ac2dd997977034"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
