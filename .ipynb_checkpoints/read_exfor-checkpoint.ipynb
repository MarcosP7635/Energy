{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.webio.node+json": {
       "children": [],
       "instanceArgs": {
        "namespace": "html",
        "tag": "div"
       },
       "nodeType": "DOM",
       "props": {},
       "type": "node"
      },
      "text/html": [
       "<div style=\"padding: 1em; background-color: #f8d6da; border: 1px solid #f5c6cb; font-weight: bold;\">\n",
       "<p>The WebIO Jupyter extension was not detected. See the\n",
       "<a href=\"https://juliagizmos.github.io/WebIO.jl/latest/providers/ijulia/\" target=\"_blank\">\n",
       "    WebIO Jupyter integration documentation\n",
       "</a>\n",
       "for more information.\n",
       "</div>\n"
      ],
      "text/plain": [
       "WebIO._IJuliaInit()"
      ]
     },
     "metadata": {
      "application/vnd.webio.node+json": {
       "kernelId": "95e8e321-5039-4c87-ae61-a139039347b7"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Unitful #https://painterqubits.github.io/Unitful.jl/stable/\n",
    "#quantity * @u_str(\"unit abbreviation\") \n",
    "using Symbolics #https://symbolics.juliasymbolics.org/dev/\n",
    "#cite https://doi.org/10.48550/arXiv.2105.03949\n",
    "using Latexify\n",
    "using Test\n",
    "#1 * @u_str(\"mA\") is 1 milliamp\n",
    "using CSV, DataFrames\n",
    "using PlotlyJS\n",
    "using SymPy\n",
    "using Interpolations\n",
    "using Plots\n",
    "using Interact\n",
    "using Statistics\n",
    "using PyCall\n",
    "py_display = pyimport(\"IPython.display\")\n",
    "using Shell\n",
    "#plotlyjs()\n",
    "data_dir = \"C:\\\\Cross-Section-Data\\\\EXFOR\\\\\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This website is made from a Jupyter notebook uses Julia instead of Python to compile faster. \n",
    "Additionally, it automatically uploads plots to a different website, with links included below :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Design\n",
    "\n",
    "    Looping check_line() through each line in the file detects where each dataset begins. \n",
    "\n",
    "    Reading the line above each output of check_line() gives the number of rows in each dataset.\n",
    "\n",
    "    make_spacing_dict() gets the names of the columns and the instructions for how to read each dataset.\n",
    "\n",
    "    read_dataset() reads each and constructs a dictionary from each dataset.\n",
    "    \n",
    "    read_exfor_file() runs all of the above in order to return a single DataFrame of all the data stored at a given file path.\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"ReferYY\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replace(\"Refer (YY)\", \" \" => \"\", \"(\" => \"\", \")\" => \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_datum (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_line(line, start)\n",
    "    if length(line) > length(start) - 1\n",
    "        return (line[1:length(start)] == start)\n",
    "    end\n",
    "    return false\n",
    "end\n",
    "\n",
    "function make_spacing_dict(line1, line2)\n",
    "    spacing_ends = [collect(out)[1] for out in findall(\">\", line2)]\n",
    "    spacing_starts = append!([1], [collect(out)[1] for out in findall(\"<\", line2)])\n",
    "    #Find where some of the spacings begin and end based on the arrows\n",
    "    if length(spacing_ends) != length(spacing_starts)\n",
    "        print(\"Error: improper formatting\")\n",
    "        return \n",
    "    end\n",
    "    indices_with_gaps = [index for index in  1:length(spacing_ends)-1 if \n",
    "                    spacing_ends[index] != spacing_starts[index+1]-1]\n",
    "    #Some of the spacings are instead denoted by the letter o instead of arrows\n",
    "    missing_spacings = [spacing_ends[index]+1:spacing_starts[index+1]-1 for index in indices_with_gaps]\n",
    "    spacings = append!(missing_spacings, \n",
    "    [spacing_starts[i]:spacing_ends[i] for i in 1:length(spacing_ends)])\n",
    "    spacing_dict = Dict([])\n",
    "    replace_dict = \n",
    "    #Make a dictionary where the keys are name for each column and the values are the indices of the columns\n",
    "    spacing_names = [spacing_dict[replace(strip(line1[spacing], [' ', '#']),\n",
    "                     \" \" => \"\", \"(\" => \"\", \")\" => \"\")] = \n",
    "                        spacing for spacing in spacings]\n",
    "    return spacing_dict\n",
    "end\n",
    "\n",
    "function read_datum(datum)\n",
    "    #Reads a single datum from a line of data\n",
    "    datum = strip(datum, [' '])\n",
    "    out = tryparse(Float64, datum)\n",
    "    if out == nothing\n",
    "        return datum \n",
    "    end\n",
    "    return out\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_spacings (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function check_spacings(file_path)\n",
    "    #Reads an EXFOR file and returns a dictionary of data\n",
    "    file_as_vector = readlines(file_path)\n",
    "    spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "                        if check_line(file_as_vector[index], \"# Prj\")]\n",
    "    if spacing_specifiers == []\n",
    "        print(\"Error: no data found\")\n",
    "        return\n",
    "    end\n",
    "    list_spacing_dict = [make_spacing_dict(file_as_vector[spacing_specifier], \n",
    "                                            file_as_vector[spacing_specifier+1])\n",
    "                        for spacing_specifier in spacing_specifiers]\n",
    "    #check if the spacing dicts are the same\n",
    "    for index in 2:length(spacing_specifiers)\n",
    "        if list_spacing_dict[index] != list_spacing_dict[1]\n",
    "            return false\n",
    "        end\n",
    "    end\n",
    "    return true\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is true that the spacings in each file are all self consistent for the subdirectory alphas\\\n",
      "It is true that the spacings in each file are all self consistent for the subdirectory deuterons\\\n",
      "It is true that the spacings in each file are all self consistent for the subdirectory gammas\\\n",
      "It is true that the spacings in each file are all self consistent for the subdirectory helions\\\n",
      "It is true that the spacings in each file are all self consistent for the subdirectory neutrons\\\n",
      "It is true that the spacings in each file are all self consistent for the subdirectory other\\\n",
      "It is true that the spacings in each file are all self consistent for the subdirectory protons\\\n"
     ]
    }
   ],
   "source": [
    "subdirs = [content * \"\\\\\" for content in readdir(data_dir) if isdir(data_dir * \"\\\\\" * content)]\n",
    "for subdir in subdirs\n",
    "    files = readdir(data_dir * subdir)\n",
    "    test = [check_spacings(data_dir * subdir * file) for file in files]\n",
    "    println(\"It is \", all(test),\n",
    "     \" that the spacings in each file are all self consistent for the subdirectory \", subdir)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I only need to retrieve the spacings of the data once for each file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_MT (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_MT(spacing_specifier, file_as_vector)\n",
    "    for lines_above in 1:10\n",
    "        if file_as_vector[spacing_specifier - lines_above][1:3] == \"#MT\"\n",
    "            return tryparse(Int64, \n",
    "                    file_as_vector[spacing_specifier - lines_above][4:end])\n",
    "        end\n",
    "    end\n",
    "    return nothing \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "read_exfor_file (generic function with 3 methods)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function read_exfor_file(file_path, filter_by_MTs = false, MTs=[])\n",
    "    #Reads an EXFOR file and returns a dictionary of data\n",
    "    file_as_vector = readlines(file_path)\n",
    "    if filter_by_MTs\n",
    "        spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "                            if check_line(file_as_vector[index], \"# Prj\")\n",
    "                                && get_MT(index, file_as_vector) in MTs]\n",
    "    else\n",
    "        spacing_specifiers = [index for index in 1:length(file_as_vector) \n",
    "                            if check_line(file_as_vector[index], \"# Prj\")]\n",
    "    end\n",
    "    #The MT line doesn't have a fixed location but is generally < 10 lines above the spacing specifier\n",
    "    if spacing_specifiers == []\n",
    "        print(\"Error: no data found\")\n",
    "        return\n",
    "    end\n",
    "    dataset_rows = [tryparse(Int64, split(file_as_vector[index - 1], [' '])[end])\n",
    "                            for index in spacing_specifiers]\n",
    "    #Each dataset should have the same column names\n",
    "    spacing_dict = make_spacing_dict(file_as_vector[spacing_specifiers[1]], \n",
    "                    file_as_vector[spacing_specifiers[1] + 1])\n",
    "    #make an empty dataframe to fill up with the data\n",
    "    df = DataFrame([Vector{Union{Missing, Float64, String, SubString{String}}}(\n",
    "                missing, sum(dataset_rows)) \n",
    "                   for _ in 1:length(keys(spacing_dict))], \n",
    "                   [key for key in keys(spacing_dict)])\n",
    "    #make a nested vector, then flatten it to populate the dataframe.\n",
    "    _ = [df[:,key] = collect(Iterators.flatten([[read_datum(\n",
    "                    file_as_vector[line_num][spacing_dict[key]]) \n",
    "                    for line_num in spacing_specifiers[index] + 2: \n",
    "                            spacing_specifiers[index] + 1 + dataset_rows[index]]\n",
    "                            for index in 1:length(spacing_specifiers)]))\n",
    "                    for key in keys(spacing_dict)]           \n",
    "    return df\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "export_plot (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_dir = \"C:\\\\Users\\\\engin\\\\Documents\\\\GitHub\\\\plots\\\\\"\n",
    "function export_plot(fig, plot_name)\n",
    "    path = website_dir * plot_name * \".html\" \n",
    "    try\n",
    "        touch(path)\n",
    "    catch\n",
    "        print(path, \" already exists. It will now be overwritten.\")\n",
    "    end\n",
    "    open(path, \"w\") do io\n",
    "        PlotlyBase.to_html(io, fig.plot)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = website_dir * \"index\" * \".html\"\n",
    "lines = readlines(path)\n",
    "end_index = [index for index in 1:length(lines) \n",
    "        if lines[index] == \"  </ul>\"]\n",
    "open(path, \"w\") do f\n",
    "    for index in 1:length(lines)\n",
    "        if index != end_index\n",
    "            println(f, lines[index])\n",
    "        else\n",
    "            println(\"\")\n",
    "        end\n",
    "    end\n",
    "end # the file f is automatically closed after this block finishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>6 rows × 18 columns (omitted printing of 10 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Targ</th><th>Entry</th><th>dCos/LO</th><th>I78</th><th>dEnergy</th><th>dELV/HL</th><th>M</th><th>ReferYY</th></tr><tr><th></th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th><th title=\"Union{Missing, Float64, SubString{String}, String}\">Union…?</th></tr></thead><tbody><tr><th>1</th><td>5010.0</td><td>M0408</td><td></td><td></td><td>1.3500+7</td><td></td><td></td><td>T.Suda,ET.AL. (88)</td></tr><tr><th>2</th><td>5010.0</td><td>M0408</td><td></td><td></td><td>1.3500+7</td><td></td><td></td><td>T.Suda,ET.AL. (88)</td></tr><tr><th>3</th><td>5010.0</td><td>M0408</td><td></td><td></td><td>1.3500+7</td><td></td><td></td><td>T.Suda,ET.AL. (88)</td></tr><tr><th>4</th><td>5010.0</td><td>M0408</td><td></td><td></td><td>1.3500+7</td><td></td><td></td><td>T.Suda,ET.AL. (88)</td></tr><tr><th>5</th><td>5010.0</td><td>M0408</td><td></td><td></td><td>1.3500+7</td><td></td><td></td><td>T.Suda,ET.AL. (88)</td></tr><tr><th>6</th><td>5010.0</td><td>M0408</td><td></td><td></td><td>1.3500+7</td><td></td><td></td><td>T.Suda,ET.AL. (88)</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccccc}\n",
       "\t& Targ & Entry & dCos/LO & I78 & dEnergy & dELV/HL & M & ReferYY & \\\\\n",
       "\t\\hline\n",
       "\t& Union…? & Union…? & Union…? & Union…? & Union…? & Union…? & Union…? & Union…? & \\\\\n",
       "\t\\hline\n",
       "\t1 & 5010.0 & M0408 &  &  & 1.3500+7 &  &  & T.Suda,ET.AL. (88) & $\\dots$ \\\\\n",
       "\t2 & 5010.0 & M0408 &  &  & 1.3500+7 &  &  & T.Suda,ET.AL. (88) & $\\dots$ \\\\\n",
       "\t3 & 5010.0 & M0408 &  &  & 1.3500+7 &  &  & T.Suda,ET.AL. (88) & $\\dots$ \\\\\n",
       "\t4 & 5010.0 & M0408 &  &  & 1.3500+7 &  &  & T.Suda,ET.AL. (88) & $\\dots$ \\\\\n",
       "\t5 & 5010.0 & M0408 &  &  & 1.3500+7 &  &  & T.Suda,ET.AL. (88) & $\\dots$ \\\\\n",
       "\t6 & 5010.0 & M0408 &  &  & 1.3500+7 &  &  & T.Suda,ET.AL. (88) & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×18 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Targ    \u001b[0m\u001b[1m Entry   \u001b[0m\u001b[1m dCos/LO \u001b[0m\u001b[1m I78     \u001b[0m\u001b[1m dEnergy  \u001b[0m\u001b[1m dELV/HL \u001b[0m\u001b[1m M       \u001b[0m\u001b[1m ReferYY\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…?  \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…? \u001b[0m\u001b[90m Union…?\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ 5010.0   M0408                      1.3500+7                    T.Suda, ⋯\n",
       "   2 │ 5010.0   M0408                      1.3500+7                    T.Suda,\n",
       "   3 │ 5010.0   M0408                      1.3500+7                    T.Suda,\n",
       "   4 │ 5010.0   M0408                      1.3500+7                    T.Suda,\n",
       "   5 │ 5010.0   M0408                      1.3500+7                    T.Suda, ⋯\n",
       "   6 │ 5010.0   M0408                      1.3500+7                    T.Suda,\n",
       "\u001b[36m                                                              11 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boron_df = read_exfor_file(data_dir * \"gammas\\\\005_B_010.c4\", true, [103])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_irregular_datum(datum, symbol)\n",
    "    if typeof(datum) == Float64\n",
    "        return datum\n",
    "    end\n",
    "    arr = split(datum, symbol)\n",
    "    if symbol == \"-\"\n",
    "        return parse(Float64, arr[1]) / 10^parse(Int64, arr[2])\n",
    "    elseif symbol == \"+\"\n",
    "        return parse(Float64, arr[1]) * 10^parse(Int64, arr[2])\n",
    "    end\n",
    "end\n",
    "boron_df[!,\"Data\"] = [read_irregular_datum(element, \"-\") for element in boron_df[!,\"Data\"]]\n",
    "boron_df[!,\"Energy\"] = [read_irregular_datum(element, \"+\") for element in boron_df[!,\"Energy\"]]\n",
    "fig = PlotlyJS.plot(boron_df, x=:Energy, y=:Data, color=:MT, text=:ReferYY,\n",
    "                mode=\"markers\", Layout(yaxis_type=\"log\", xaxis_type=\"log\"));\n",
    "export_plot(fig, \"plot3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exports the plot, displays it by borrowing functionality from python, and backs it up to a website with the same functionality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the legend to view different MTs :) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://marcosp7635.github.io/plots/plot1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1000\"\n",
       "            height=\"1000\"\n",
       "            src=\"plot1.html\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "PyObject <IPython.lib.display.IFrame object at 0x00000000D0393A90>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py_display.IFrame(src = \"plot1.html\", width = 1000, height = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = data_dir * \"neutrons\\\\092_U_238.c4\"\n",
    "df = read_exfor_file(file_path, true, [1, 2, 102])\n",
    "fig = PlotlyJS.plot(df, x=:Energy, y=:Data, color=:MT, text=:ReferYY,\n",
    "                mode=\"markers\", Layout(yaxis_type=\"log\", xaxis_type=\"log\"));\n",
    "export_plot(fig, \"plot2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://marcosp7635.github.io/plots/plot2.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "py_display.IFrame(src = \"plot2.html\", width = 1000, height = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[main d8c4644] 'exported'\n",
      " 5 files changed, 85 insertions(+), 8 deletions(-)\n",
      " create mode 100644 MathJax.js\n",
      " create mode 100644 plotly-2.3.0.min.js\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in plot1.html.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in plot2.html.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in plot3.html.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in MathJax.js.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in plotly-2.3.0.min.js.\n",
      "The file will have its original line endings in your working directory\n",
      "To https://github.com/MarcosP7635/plots.git\n",
      "   a99587b..d8c4644  main -> main\n"
     ]
    }
   ],
   "source": [
    "Shell.run(\"git -C \" * website_dir * \" add *\")\n",
    "Shell.run(\"git -C \" * website_dir * \" commit -am 'exported'\")\n",
    "Shell.run(\"git -C \" * website_dir * \" push\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://marcosp7635.github.io/plots/neutrons_U238.html\n",
    "\n",
    "https://interactive-data-mp7635.herokuapp.com/neutrons-U238"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": "7ca7935239704c1f8c6e3d20cdfc0c74",
   "lastKernelId": "95e8e321-5039-4c87-ae61-a139039347b7"
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "93e603b405028e2ab398d7a85d86124a7ac0b053113ed31068605d4be5533369"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
